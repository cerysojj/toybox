{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import os\n","os.chdir(\"/content/drive/MyDrive/ug-project/src\")\n","!pwd\n","%load_ext autoreload\n","%autoreload 2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2EoQjvbchYst","outputId":"5c4974dc-b6d6-45e8-ee73-37a023d91c54"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/ug-project/src\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S725bwhPOhbv"},"outputs":[],"source":["import os\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import matplotlib.pyplot as plt\n","import torchvision.transforms as v2\n","from torch.utils.data import DataLoader\n","from datasets import DatasetIN100, IN_MEAN, IN_STD\n","\n","# Hyperparameters\n","learning_rate = 0.001\n","epochs = 50\n","batch_size = 256\n","\n","# Where to save checkpoints and logs\n","output_dir = \"/content/drive/MyDrive/ug-project/output/IN100_clear_final\"\n","os.makedirs(output_dir, exist_ok=True)"]},{"cell_type":"code","source":["prob = 0.2\n","color_transforms = [v2.RandomApply([v2.ColorJitter(brightness=0.2)], p=prob),\n","                    v2.RandomApply([v2.ColorJitter(hue=0.2)], p=prob),\n","                    v2.RandomApply([v2.ColorJitter(saturation=0.2)], p=prob),\n","                    v2.RandomApply([v2.ColorJitter(contrast=0.2)], p=prob),\n","                    v2.RandomEqualize(p=prob),\n","                    v2.RandomPosterize(bits=4, p=prob),\n","                    v2.RandomAutocontrast(p=prob)\n","                    ]\n","transform = v2.Compose([v2.ToPILImage(),\n","                        v2.Resize((256, 256)),\n","                        v2.RandomResizedCrop(size=(224, 224), scale=(0.5, 1.0), interpolation=v2.InterpolationMode.BICUBIC),\n","                        v2.RandomOrder(color_transforms),\n","                        v2.RandomHorizontalFlip(),\n","                        v2.ToTensor(),\n","                        v2.Normalize(mean=IN_MEAN, std=IN_STD),\n","                        v2.RandomErasing(p=0.5)\n","                        ])\n","transform_test = v2.Compose([\n","    v2.ToPILImage(),\n","    v2.Resize((224, 224)),\n","    v2.ToTensor(),\n","    v2.Normalize(mean=IN_MEAN, std=IN_STD)\n","])"],"metadata":{"id":"sHzybktiO7E_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset = DatasetIN100(train=True, transform=transform, fraction=0.3)\n","val_dataset = DatasetIN100(train=False, transform=transform_test)\n","\n","print(f\"Training set size: {len(train_dataset)}\")\n","print(f\"Validation set size: {len(val_dataset)}\")\n","\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True, drop_last=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True, drop_last=True)"],"metadata":{"id":"SNX7akE_OvdE","colab":{"base_uri":"https://localhost:8080/"},"outputId":"76bce3ef-f51c-4397-eb39-c3f3b8e8a5da"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training set size: 39000\n","Validation set size: 5000\n"]}]},{"cell_type":"code","source":["from model import ResNet18Sup\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Create a ResNet18 model for 100 classes.\n","model = ResNet18Sup(num_classes=100).to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n","\n","# Set up learning rate schedulers\n","steps = len(train_loader)\n","warmup_scheduler = torch.optim.lr_scheduler.LinearLR(optimizer=optimizer, start_factor=0.01,\n","                                                       end_factor=1.0, total_iters=2*steps)\n","decay_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer,\n","                                                             T_max=(epochs - 2)*steps)\n","combined_scheduler = torch.optim.lr_scheduler.SequentialLR(optimizer=optimizer,\n","                                                           schedulers=[warmup_scheduler, decay_scheduler],\n","                                                           milestones=[2*steps+1])"],"metadata":{"id":"3pQvhBlmPJuv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Evaluate model before training"],"metadata":{"id":"q-__cm9-Q6N9"}},{"cell_type":"code","source":["model.eval()\n","train_loss, train_correct, total_train = 0, 0, 0\n","\n","with torch.no_grad():\n","    for images, labels in train_loader:\n","        images, labels = images.to(device), labels.to(device)\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        train_loss += loss.item() * images.size(0)\n","        _, predicted = torch.max(outputs.data, 1)\n","        train_correct += (predicted == labels).sum().item()\n","        total_train += labels.size(0)\n","\n","avg_train_loss = train_loss / total_train\n","train_accuracy = (train_correct / total_train) * 100\n","\n","val_loss, val_correct, total_val = 0, 0, 0\n","with torch.no_grad():\n","    for images, labels in val_loader:\n","        images, labels = images.to(device), labels.to(device)\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        val_loss += loss.item() * images.size(0)\n","        _, predicted = torch.max(outputs.data, 1)\n","        val_correct += (predicted == labels).sum().item()\n","        total_val += labels.size(0)\n","\n","avg_val_loss = val_loss / total_val\n","val_accuracy = (val_correct / total_val) * 100\n","\n","print(f\"Before Training: Train Loss: {avg_train_loss:.4f}, Train Acc: {train_accuracy:.2f}%\")\n","print(f\"Before Training: Val Loss: {avg_val_loss:.4f}, Val Acc: {val_accuracy:.2f}%\")"],"metadata":{"id":"gL7h_jxDPMEv","colab":{"base_uri":"https://localhost:8080/","height":738},"outputId":"900bcb89-1320-4e59-c9d8-54612e1bf628"},"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/worker.py\", line 351, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\", line 55, in fetch\n    return self.collate_fn(data)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\", line 398, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\", line 211, in collate\n    return [\n           ^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\", line 212, in <listcomp>\n    collate(samples, collate_fn_map=collate_fn_map)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\", line 155, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\", line 272, in collate_tensor_fn\n    return torch.stack(batch, 0, out=out)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: stack expects each tensor to be equal size, but got [3, 224, 298] at entry 0 and [3, 224, 280] at entry 9\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-0b0bdb07d0f7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_correct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1463\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1464\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1465\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1467\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1489\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1490\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1491\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1492\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    713\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 715\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/worker.py\", line 351, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\", line 55, in fetch\n    return self.collate_fn(data)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\", line 398, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\", line 211, in collate\n    return [\n           ^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\", line 212, in <listcomp>\n    collate(samples, collate_fn_map=collate_fn_map)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\", line 155, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\", line 272, in collate_tensor_fn\n    return torch.stack(batch, 0, out=out)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: stack expects each tensor to be equal size, but got [3, 224, 298] at entry 0 and [3, 224, 280] at entry 9\n"]}]},{"cell_type":"markdown","source":["## Training loop"],"metadata":{"id":"DMFjBdUbQ4cG"}},{"cell_type":"code","source":["# Lists for tracking metrics\n","train_losses, train_accuracies = [], []\n","val_losses, val_accuracies = [], []\n","logs = []\n","\n","for epoch in range(epochs):\n","    model.train()\n","    for images, labels in train_loader:\n","        images, labels = images.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        combined_scheduler.step()\n","\n","    # Evaluate on training set\n","    model.eval()\n","    train_loss, train_correct, total_train = 0, 0, 0\n","    with torch.no_grad():\n","        for images, labels in train_loader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            train_loss += loss.item() * images.size(0)\n","            _, predicted = torch.max(outputs.data, 1)\n","            train_correct += (predicted == labels).sum().item()\n","            total_train += labels.size(0)\n","    avg_train_loss = train_loss / total_train\n","    train_acc = (train_correct / total_train) * 100\n","\n","    # Evaluate on validation set\n","    val_loss, val_correct, total_val = 0, 0, 0\n","    with torch.no_grad():\n","        for images, labels in val_loader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            val_loss += loss.item() * images.size(0)\n","            _, predicted = torch.max(outputs.data, 1)\n","            val_correct += (predicted == labels).sum().item()\n","            total_val += labels.size(0)\n","    avg_val_loss = val_loss / total_val\n","    val_acc = (val_correct / total_val) * 100\n","\n","    train_losses.append(avg_train_loss)\n","    train_accuracies.append(train_acc)\n","    val_losses.append(avg_val_loss)\n","    val_accuracies.append(val_acc)\n","\n","    log_entry = (f\"Epoch {epoch+1}/{epochs}: Train Loss: {avg_train_loss:.4f}, \"\n","                 f\"Train Acc: {train_acc:.2f}%, Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n","    print(log_entry)\n","    logs.append(log_entry)\n","\n","    # Save checkpoint every 10 epochs\n","    if (epoch+1) % 10 == 0:\n","        checkpoint_path = os.path.join(output_dir, f'model_checkpoint_epoch{epoch+1}.pth')\n","        checkpoint = {\n","            'epoch': epoch+1,\n","            'model_state_dict': model.state_dict(),\n","            'optimizer_state_dict': optimizer.state_dict(),\n","            'train_loss': avg_train_loss,\n","            'train_accuracy': train_acc,\n","        }\n","        torch.save(checkpoint, checkpoint_path)"],"metadata":{"id":"okoj5uDRQ2cQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Save logs and plot metrics"],"metadata":{"id":"gPJVzF6aRCTq"}},{"cell_type":"code","source":["import pickle\n","\n","# Save training logs\n","with open(os.path.join(output_dir, \"training_log.txt\"), 'w') as f:\n","    for entry in logs:\n","        f.write(entry + \"\\n\")\n","\n","# Save metrics for later analysis\n","metrics = {\n","    'train_losses': train_losses,\n","    'train_accuracies': train_accuracies,\n","    'val_losses': val_losses,\n","    'val_accuracies': val_accuracies\n","}\n","with open(os.path.join(output_dir, \"metrics.pkl\"), \"wb\") as f:\n","    pickle.dump(metrics, f)"],"metadata":{"id":"5EGe63LDREnA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot loss curves\n","plt.figure(figsize=(15, 6))\n","plt.plot(train_losses, label='Train Loss')\n","plt.plot(val_losses, label='Val Loss')\n","plt.title('Loss for ResNet18 trained on Clear ImageNet-100 Images')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"525-UJx1eQOb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot accuracy curves\n","plt.figure(figsize=(15, 6))\n","plt.plot(train_accuracies, label='Train Accuracy')\n","plt.plot(val_accuracies, label='Val Accuracy')\n","plt.title('Accuracy for ResNet18 trained on Clear ImageNet-100 Images')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy (%)')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"7uAv4NhLtXBK"},"execution_count":null,"outputs":[]}]}