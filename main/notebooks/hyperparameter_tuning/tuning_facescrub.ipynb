{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","mount_file_id":"1YGu-C-liy6HsXJuB7qut-M_ZbjyXsR7V","authorship_tag":"ABX9TyPfmcMlICrmC9HPKYcCAVIP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"f8f2g1VCXqzq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741129438706,"user_tz":0,"elapsed":201,"user":{"displayName":"Cerys Jenkins","userId":"06351033700281528774"}},"outputId":"71d3d1af-ca3c-420c-be9e-ba1d322006b0"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/ug-project/src\n"]}],"source":["import os\n","os.chdir(\"/content/drive/MyDrive/ug-project/src\")\n","!pwd\n","%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RaAoFBc6o3B4","executionInfo":{"status":"ok","timestamp":1741117373327,"user_tz":0,"elapsed":10314,"user":{"displayName":"Cerys Jenkins","userId":"06351033700281528774"}},"outputId":"77813059-8e32-4d5b-ad9c-cd17cb651271"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["from datasets import FaceScrubDataset, FACESCRUB_MEAN, FACESCRUB_STD\n","import numpy as np\n","import torchvision.transforms.v2 as v2\n","from torchvision import datasets\n","from torch.utils.data import DataLoader, random_split"],"metadata":{"id":"9oPjXxJLXssh","executionInfo":{"status":"ok","timestamp":1741129450085,"user_tz":0,"elapsed":10716,"user":{"displayName":"Cerys Jenkins","userId":"06351033700281528774"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["### Set hyperparameters"],"metadata":{"id":"cU4MlXwqgBUc"}},{"cell_type":"code","source":["learning_rate = (0.05, 0.01, 0.005, 0.001)\n","epochs = 20\n","batch_size = 256"],"metadata":{"id":"aQZ3vDD-Z7p4","executionInfo":{"status":"ok","timestamp":1741129450095,"user_tz":0,"elapsed":8,"user":{"displayName":"Cerys Jenkins","userId":"06351033700281528774"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["### Define transforms"],"metadata":{"id":"BN8erByogEsI"}},{"cell_type":"code","source":["prob = 0.2\n","color_transforms = [v2.RandomApply([v2.ColorJitter(brightness=0.2)], p=prob),\n","                    v2.RandomApply([v2.ColorJitter(hue=0.2)], p=prob),\n","                    v2.RandomApply([v2.ColorJitter(saturation=0.2)], p=prob),\n","                    v2.RandomApply([v2.ColorJitter(contrast=0.2)], p=prob),\n","                    v2.RandomEqualize(p=prob),\n","                    v2.RandomPosterize(bits=4, p=prob),\n","                    v2.RandomAutocontrast(p=prob)\n","                    ]\n","transform = v2.Compose([v2.ToPILImage(),\n","                        v2.Resize((256, 256)),\n","                        v2.RandomResizedCrop(size=224, scale=(0.5, 1.0), interpolation=v2.InterpolationMode.BICUBIC),\n","                        v2.RandomOrder(color_transforms),\n","                        v2.RandomHorizontalFlip(),\n","                        v2.ToTensor(),\n","                        v2.Normalize(mean=FACESCRUB_MEAN, std=FACESCRUB_STD),\n","                        v2.RandomErasing(p=0.5)\n","                        ])\n","transform_test = v2.Compose([\n","    v2.ToPILImage(),\n","    v2.Resize(224),\n","    v2.ToTensor(),\n","    v2.Normalize(mean=FACESCRUB_MEAN, std=FACESCRUB_STD)\n","])"],"metadata":{"id":"X-OVuBAcXvPp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741129450173,"user_tz":0,"elapsed":77,"user":{"displayName":"Cerys Jenkins","userId":"06351033700281528774"}},"outputId":"a50138c7-5c7a-489b-d0c8-40b47cfac22f"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n","  warnings.warn(\n"]}]},{"cell_type":"markdown","source":["### Load FaceScrub dataset"],"metadata":{"id":"3uVOgn6BgIwX"}},{"cell_type":"code","source":["train_dataset = FaceScrubDataset(train=True, hypertune=True, transform=transform)\n","print(f\"Dev set size: {len(train_dataset)}\")\n","\n","val_dataset = FaceScrubDataset(train=False, hypertune=True, transform=transform_test)\n","print(f\"Val set size: {len(val_dataset)}\")\n","\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True, drop_last=True, persistent_workers=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True, drop_last=True, persistent_workers=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VNooYKDfYh7D","executionInfo":{"status":"ok","timestamp":1741129462755,"user_tz":0,"elapsed":12579,"user":{"displayName":"Cerys Jenkins","userId":"06351033700281528774"}},"outputId":"850e509c-b46d-43fe-d195-6a8d33f13d24"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Dev set size: 34517\n","Val set size: 4314\n"]}]},{"cell_type":"markdown","source":["### Create ResNet18 model"],"metadata":{"id":"BxsY-xvSgLtm"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from model import ResNet18Sup\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","criterion = nn.CrossEntropyLoss()\n","steps = len(train_loader)"],"metadata":{"id":"2_KSTVFuYrAl","executionInfo":{"status":"ok","timestamp":1741129463162,"user_tz":0,"elapsed":406,"user":{"displayName":"Cerys Jenkins","userId":"06351033700281528774"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["### Loop through learning rates"],"metadata":{"id":"ayot1qVfa1yE"}},{"cell_type":"code","source":["for lr in learning_rate:\n","    print(f\"Learning rate: {lr}\")\n","    model = ResNet18Sup(num_classes=530).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n","    warmup_scheduler = torch.optim.lr_scheduler.LinearLR(optimizer=optimizer, start_factor=0.01, end_factor=1.0,\n","                                                          total_iters=2*steps)\n","    decay_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer, T_max=(epochs - 2) * steps)\n","    combined_scheduler = torch.optim.lr_scheduler.SequentialLR(optimizer=optimizer,\n","                                                                schedulers=[warmup_scheduler, decay_scheduler],\n","                                                                milestones=[2*steps+1])\n","\n","    # Initialize metrics for ploting\n","    train_losses, train_correct = [], []\n","    val_losses, val_correct = [], []\n","\n","    for epoch in range(0, epochs):\n","\n","        ###################### Train model #########################\n","        model.train()\n","        for _, images, labels in train_loader:\n","            images, labels = images.to(device), labels.to(device)\n","            optimizer.zero_grad()\n","            logits = model(images)\n","            loss = criterion(logits, labels)\n","            loss.backward()\n","            optimizer.step()\n","            combined_scheduler.step()\n","\n","        # Evaluate on training set\n","        model.eval()\n","        train_loss, train_corr, total_train = 0, 0, 0\n","\n","        with torch.no_grad():\n","            for _, images, labels in train_loader:\n","                images, labels = images.to(device), labels.to(device)\n","\n","                y_pred = model(images)\n","                loss = criterion(y_pred, labels)\n","\n","                train_loss += loss.item() * images.size(0)\n","                predicted = torch.max(y_pred.data, 1)[1]\n","                train_corr += (predicted == labels).sum().item()\n","                total_train += labels.size(0)\n","\n","        avg_train_loss = train_loss / total_train\n","        train_accuracy = (train_corr / total_train) * 100\n","\n","        ###################### Evaluate model ######################\n","        val_loss, val_corr, total_val = 0, 0, 0\n","\n","        with torch.no_grad():\n","            for _, images, labels in val_loader:\n","                images, labels = images.to(device), labels.to(device)\n","\n","                y_val_pred = model(images)\n","                loss = criterion(y_val_pred, labels)\n","\n","                val_loss += loss.item() * images.size(0)\n","                predicted = torch.max(y_val_pred, 1)[1]\n","                val_corr += (predicted == labels).sum().item()\n","                total_val += labels.size(0)\n","\n","\n","        avg_val_loss = val_loss / total_val\n","        val_accuracy = (val_corr / total_val) * 100\n","\n","        # Save results of current epoch\n","        train_losses.append(avg_train_loss)\n","        train_correct.append(train_accuracy)\n","        val_losses.append(avg_val_loss)\n","        val_correct.append(val_accuracy)\n","\n","        # Add epoch results to log file\n","        log_entry = (f\"Epoch {epoch+1}/{epochs}, Train Loss: {avg_train_loss:.4f}, Train Acc: {train_accuracy:.2f}, Val Loss: {avg_val_loss:.4f}, Val Acc: {val_accuracy:.2f}%\")\n","        print(log_entry)"],"metadata":{"id":"IdYwRetiaD1J","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741147867974,"user_tz":0,"elapsed":18404810,"user":{"displayName":"Cerys Jenkins","userId":"06351033700281528774"}},"outputId":"c22318d4-070a-4afc-eb6a-c1b6144e31e2"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Learning rate: 0.05\n","Epoch 1/20, Train Loss: 6.2205, Train Acc: 0.62, Val Loss: 6.6778, Val Acc: 0.32%\n","Epoch 2/20, Train Loss: 6.1615, Train Acc: 1.70, Val Loss: 8.6967, Val Acc: 0.61%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:240: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3/20, Train Loss: 5.2474, Train Acc: 3.62, Val Loss: 7.5430, Val Acc: 1.10%\n","Epoch 4/20, Train Loss: 4.6657, Train Acc: 7.82, Val Loss: 8.5054, Val Acc: 2.34%\n","Epoch 5/20, Train Loss: 4.1303, Train Acc: 14.14, Val Loss: 8.5244, Val Acc: 3.98%\n","Epoch 6/20, Train Loss: 3.8894, Train Acc: 18.50, Val Loss: 10.4373, Val Acc: 4.98%\n","Epoch 7/20, Train Loss: 4.7468, Train Acc: 12.72, Val Loss: 12.0594, Val Acc: 3.22%\n","Epoch 8/20, Train Loss: 3.3584, Train Acc: 26.03, Val Loss: 10.3480, Val Acc: 7.03%\n","Epoch 9/20, Train Loss: 2.9768, Train Acc: 33.48, Val Loss: 11.9034, Val Acc: 8.67%\n","Epoch 10/20, Train Loss: 2.6283, Train Acc: 39.29, Val Loss: 12.1204, Val Acc: 9.45%\n","Epoch 11/20, Train Loss: 2.7705, Train Acc: 37.69, Val Loss: 12.8366, Val Acc: 9.59%\n","Epoch 12/20, Train Loss: 2.0486, Train Acc: 51.67, Val Loss: 13.7111, Val Acc: 12.35%\n","Epoch 13/20, Train Loss: 1.6648, Train Acc: 59.71, Val Loss: 13.9928, Val Acc: 13.96%\n","Epoch 14/20, Train Loss: 1.4087, Train Acc: 65.09, Val Loss: 15.3248, Val Acc: 14.75%\n","Epoch 15/20, Train Loss: 1.1957, Train Acc: 70.35, Val Loss: 16.0676, Val Acc: 15.82%\n","Epoch 16/20, Train Loss: 0.9650, Train Acc: 75.89, Val Loss: 17.3943, Val Acc: 16.50%\n","Epoch 17/20, Train Loss: 0.8075, Train Acc: 79.79, Val Loss: 18.5873, Val Acc: 17.09%\n","Epoch 18/20, Train Loss: 0.7122, Train Acc: 82.37, Val Loss: 18.4762, Val Acc: 17.72%\n","Epoch 19/20, Train Loss: 0.6387, Train Acc: 84.19, Val Loss: 19.1007, Val Acc: 17.82%\n","Epoch 20/20, Train Loss: 0.6365, Train Acc: 84.30, Val Loss: 19.1457, Val Acc: 17.87%\n","Learning rate: 0.01\n","Epoch 1/20, Train Loss: 7.8467, Train Acc: 0.79, Val Loss: 8.4826, Val Acc: 0.29%\n","Epoch 2/20, Train Loss: 6.5850, Train Acc: 2.31, Val Loss: 9.6053, Val Acc: 0.54%\n","Epoch 3/20, Train Loss: 4.6237, Train Acc: 8.58, Val Loss: 9.0040, Val Acc: 2.05%\n","Epoch 4/20, Train Loss: 4.0309, Train Acc: 16.97, Val Loss: 10.3897, Val Acc: 4.03%\n","Epoch 5/20, Train Loss: 3.2577, Train Acc: 26.72, Val Loss: 10.4018, Val Acc: 6.49%\n","Epoch 6/20, Train Loss: 3.0301, Train Acc: 33.00, Val Loss: 12.7857, Val Acc: 8.06%\n","Epoch 7/20, Train Loss: 2.4678, Train Acc: 42.51, Val Loss: 12.9006, Val Acc: 9.72%\n","Epoch 8/20, Train Loss: 1.9427, Train Acc: 52.92, Val Loss: 14.6996, Val Acc: 12.23%\n","Epoch 9/20, Train Loss: 1.7413, Train Acc: 57.82, Val Loss: 14.4654, Val Acc: 13.33%\n","Epoch 10/20, Train Loss: 1.3906, Train Acc: 64.96, Val Loss: 14.6011, Val Acc: 14.09%\n","Epoch 11/20, Train Loss: 1.1880, Train Acc: 70.01, Val Loss: 16.9774, Val Acc: 15.19%\n","Epoch 12/20, Train Loss: 0.9451, Train Acc: 75.66, Val Loss: 16.6297, Val Acc: 15.84%\n","Epoch 13/20, Train Loss: 0.7067, Train Acc: 81.63, Val Loss: 18.0225, Val Acc: 17.07%\n","Epoch 14/20, Train Loss: 0.5757, Train Acc: 85.18, Val Loss: 18.1019, Val Acc: 17.46%\n","Epoch 15/20, Train Loss: 0.5039, Train Acc: 86.57, Val Loss: 19.2485, Val Acc: 17.85%\n","Epoch 16/20, Train Loss: 0.3958, Train Acc: 89.70, Val Loss: 19.2843, Val Acc: 18.29%\n","Epoch 17/20, Train Loss: 0.3142, Train Acc: 91.92, Val Loss: 19.6818, Val Acc: 18.55%\n","Epoch 18/20, Train Loss: 0.2739, Train Acc: 93.04, Val Loss: 20.1692, Val Acc: 18.77%\n","Epoch 19/20, Train Loss: 0.2578, Train Acc: 93.40, Val Loss: 20.2205, Val Acc: 18.75%\n","Epoch 20/20, Train Loss: 0.2547, Train Acc: 93.41, Val Loss: 20.2579, Val Acc: 18.82%\n","Learning rate: 0.005\n","Epoch 1/20, Train Loss: 6.5410, Train Acc: 0.84, Val Loss: 7.5761, Val Acc: 0.20%\n","Epoch 2/20, Train Loss: 5.4878, Train Acc: 2.55, Val Loss: 7.4102, Val Acc: 0.71%\n","Epoch 3/20, Train Loss: 4.2181, Train Acc: 12.30, Val Loss: 8.8994, Val Acc: 3.42%\n","Epoch 4/20, Train Loss: 4.3729, Train Acc: 13.87, Val Loss: 10.4497, Val Acc: 2.93%\n","Epoch 5/20, Train Loss: 3.1609, Train Acc: 28.15, Val Loss: 10.2316, Val Acc: 6.35%\n","Epoch 6/20, Train Loss: 3.1798, Train Acc: 30.70, Val Loss: 13.4246, Val Acc: 7.23%\n","Epoch 7/20, Train Loss: 2.3518, Train Acc: 44.69, Val Loss: 12.0688, Val Acc: 9.94%\n","Epoch 8/20, Train Loss: 1.8242, Train Acc: 55.14, Val Loss: 14.4943, Val Acc: 11.89%\n","Epoch 9/20, Train Loss: 1.6764, Train Acc: 58.88, Val Loss: 14.4500, Val Acc: 12.99%\n","Epoch 10/20, Train Loss: 1.6349, Train Acc: 59.75, Val Loss: 16.0493, Val Acc: 14.38%\n","Epoch 11/20, Train Loss: 1.1157, Train Acc: 72.07, Val Loss: 15.2676, Val Acc: 16.02%\n","Epoch 12/20, Train Loss: 0.9088, Train Acc: 77.03, Val Loss: 16.3436, Val Acc: 16.31%\n","Epoch 13/20, Train Loss: 0.8159, Train Acc: 78.83, Val Loss: 17.2031, Val Acc: 16.33%\n","Epoch 14/20, Train Loss: 0.6173, Train Acc: 84.18, Val Loss: 17.1478, Val Acc: 17.36%\n","Epoch 15/20, Train Loss: 0.5224, Train Acc: 86.72, Val Loss: 17.6569, Val Acc: 17.65%\n","Epoch 16/20, Train Loss: 0.4651, Train Acc: 88.26, Val Loss: 18.2789, Val Acc: 18.24%\n","Epoch 17/20, Train Loss: 0.3760, Train Acc: 90.53, Val Loss: 18.3324, Val Acc: 18.43%\n","Epoch 18/20, Train Loss: 0.3435, Train Acc: 91.39, Val Loss: 18.5163, Val Acc: 18.77%\n","Epoch 19/20, Train Loss: 0.3331, Train Acc: 91.70, Val Loss: 18.3402, Val Acc: 18.73%\n","Epoch 20/20, Train Loss: 0.3205, Train Acc: 92.08, Val Loss: 18.3247, Val Acc: 18.77%\n","Learning rate: 0.001\n","Epoch 1/20, Train Loss: 6.4560, Train Acc: 1.00, Val Loss: 7.7455, Val Acc: 0.20%\n","Epoch 2/20, Train Loss: 5.2935, Train Acc: 4.21, Val Loss: 8.0010, Val Acc: 1.10%\n","Epoch 3/20, Train Loss: 4.2713, Train Acc: 12.16, Val Loss: 9.3823, Val Acc: 3.66%\n","Epoch 4/20, Train Loss: 3.7323, Train Acc: 19.86, Val Loss: 9.0676, Val Acc: 5.96%\n","Epoch 5/20, Train Loss: 3.2332, Train Acc: 27.13, Val Loss: 9.9743, Val Acc: 6.47%\n","Epoch 6/20, Train Loss: 2.4300, Train Acc: 42.85, Val Loss: 10.9617, Val Acc: 10.03%\n","Epoch 7/20, Train Loss: 2.4498, Train Acc: 42.84, Val Loss: 10.6076, Val Acc: 10.21%\n","Epoch 8/20, Train Loss: 1.8453, Train Acc: 55.28, Val Loss: 12.2334, Val Acc: 13.04%\n","Epoch 9/20, Train Loss: 1.6362, Train Acc: 59.69, Val Loss: 13.0104, Val Acc: 13.35%\n","Epoch 10/20, Train Loss: 1.6790, Train Acc: 58.76, Val Loss: 13.6057, Val Acc: 13.09%\n","Epoch 11/20, Train Loss: 1.0604, Train Acc: 73.90, Val Loss: 13.6375, Val Acc: 15.80%\n","Epoch 12/20, Train Loss: 0.9882, Train Acc: 75.23, Val Loss: 14.4424, Val Acc: 16.48%\n","Epoch 13/20, Train Loss: 0.8948, Train Acc: 77.55, Val Loss: 14.2008, Val Acc: 16.72%\n","Epoch 14/20, Train Loss: 0.8574, Train Acc: 78.61, Val Loss: 14.0454, Val Acc: 17.07%\n","Epoch 15/20, Train Loss: 0.6689, Train Acc: 83.77, Val Loss: 14.0086, Val Acc: 17.31%\n","Epoch 16/20, Train Loss: 0.5645, Train Acc: 86.56, Val Loss: 14.4726, Val Acc: 18.16%\n","Epoch 17/20, Train Loss: 0.4906, Train Acc: 88.34, Val Loss: 14.7818, Val Acc: 18.46%\n","Epoch 18/20, Train Loss: 0.4542, Train Acc: 89.48, Val Loss: 14.5610, Val Acc: 18.58%\n","Epoch 19/20, Train Loss: 0.4314, Train Acc: 90.16, Val Loss: 14.7082, Val Acc: 18.75%\n","Epoch 20/20, Train Loss: 0.4340, Train Acc: 90.02, Val Loss: 14.7327, Val Acc: 18.70%\n"]}]}]}