{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQ-80wuoKRG4",
        "outputId": "593ee0fd-7a52-45a4-d351-4f2dcf72d5b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqqvV0efI0wi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import itertools\n",
        "from matplotlib import pyplot\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import BatchNormalization\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import model_from_json\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPool2D, Dropout, MaxPooling2D, Activation, ZeroPadding2D\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from PIL import Image\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import SparseCategoricalAccuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWShWlyRJbrE"
      },
      "outputs": [],
      "source": [
        "base_frame_path = '/content/drive/MyDrive/toybox_5fold'\n",
        "\n",
        "def load_data_for_fold(fold):\n",
        "    train_list = []\n",
        "    val_list = []\n",
        "\n",
        "    fold_train_path = os.path.join(base_frame_path, f'fold_{fold}', 'train')\n",
        "    fold_val_path = os.path.join(base_frame_path, f'fold_{fold}', 'val')\n",
        "\n",
        "    directories = [fold_train_path, fold_val_path]\n",
        "    data_lists = [train_list, val_list]\n",
        "\n",
        "    unique_labels = set()\n",
        "\n",
        "    for dataset, data_list in zip(directories, data_lists):\n",
        "        for class_folder in os.listdir(dataset):\n",
        "            class_path = os.path.join(dataset, class_folder)\n",
        "\n",
        "            if os.path.isdir(class_path):\n",
        "                for frame_file in os.listdir(class_path):\n",
        "                    if frame_file.endswith('.jpg'):\n",
        "                        frame_path = os.path.join(class_path, frame_file)\n",
        "                        label = frame_file.split('_')[0]\n",
        "                        unique_labels.add(label)\n",
        "                        image_pil = Image.open(frame_path).convert('L')\n",
        "                        image_resized = image_pil.resize((224, 224))\n",
        "                        image = np.array(image_resized) / 255.0\n",
        "                        data_list.append((image, label))\n",
        "                        image_pil.close()\n",
        "\n",
        "    label_to_index = {label: idx for idx, label in enumerate(unique_labels)}\n",
        "\n",
        "    x_train, y_train = zip(*[(image, label_to_index[label]) for image, label in train_list])\n",
        "    x_test, y_test = zip(*[(image, label_to_index[label]) for image, label in val_list])\n",
        "\n",
        "    x_train = np.array(x_train).reshape(-1, 224, 224, 1)\n",
        "    y_train = np.array(y_train)\n",
        "    x_test = np.array(x_test).reshape(-1, 224, 224, 1)\n",
        "    y_test = np.array(y_test)\n",
        "\n",
        "    return (x_train, y_train), (x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ezn4GpRc7EdJ"
      },
      "outputs": [],
      "source": [
        "def create_tf_dataset(x_data, y_data, batch_size=32, shuffle=True):\n",
        "    # Create a TensorFlow dataset\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((x_data, y_data))\n",
        "\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(buffer_size=len(x_data))\n",
        "\n",
        "    # Batch the dataset\n",
        "    dataset = dataset.batch(batch_size)\n",
        "\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fB8Dhlf-bnno"
      },
      "outputs": [],
      "source": [
        "# Define the AlexNet model\n",
        "def alexnet_model(img_shape=(224, 224, 1), n_classes=12):\n",
        "\n",
        "\t# Initialize model\n",
        "\talexnet = Sequential()\n",
        "\n",
        "\t# Layer 1\n",
        "\talexnet.add(Conv2D(96, (11, 11), input_shape=img_shape,\n",
        "\t\tpadding='same', kernel_regularizer='l2'))\n",
        "\talexnet.add(BatchNormalization())\n",
        "\talexnet.add(Activation('relu'))\n",
        "\talexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\t# Layer 2\n",
        "\talexnet.add(Conv2D(256, (5, 5), padding='same'))\n",
        "\talexnet.add(BatchNormalization())\n",
        "\talexnet.add(Activation('relu'))\n",
        "\talexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\t# Layer 3\n",
        "\talexnet.add(ZeroPadding2D((1, 1)))\n",
        "\talexnet.add(Conv2D(512, (3, 3), padding='same'))\n",
        "\talexnet.add(BatchNormalization())\n",
        "\talexnet.add(Activation('relu'))\n",
        "\talexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\t# Layer 4\n",
        "\talexnet.add(ZeroPadding2D((1, 1)))\n",
        "\talexnet.add(Conv2D(1024, (3, 3), padding='same'))\n",
        "\talexnet.add(BatchNormalization())\n",
        "\talexnet.add(Activation('relu'))\n",
        "\n",
        "\t# Layer 5\n",
        "\talexnet.add(ZeroPadding2D((1, 1)))\n",
        "\talexnet.add(Conv2D(1024, (3, 3), padding='same'))\n",
        "\talexnet.add(BatchNormalization())\n",
        "\talexnet.add(Activation('relu'))\n",
        "\talexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\t# Layer 6\n",
        "\talexnet.add(Flatten())\n",
        "\talexnet.add(Dense(3072))\n",
        "\talexnet.add(BatchNormalization())\n",
        "\talexnet.add(Activation('relu'))\n",
        "\talexnet.add(Dropout(0.5))\n",
        "\n",
        "\t# Layer 7\n",
        "\talexnet.add(Dense(4096))\n",
        "\talexnet.add(BatchNormalization())\n",
        "\talexnet.add(Activation('relu'))\n",
        "\talexnet.add(Dropout(0.5))\n",
        "\n",
        "\t# Layer 8\n",
        "\talexnet.add(Dense(n_classes))\n",
        "\talexnet.add(BatchNormalization())\n",
        "\talexnet.add(Activation('softmax'))\n",
        "\n",
        "\treturn alexnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "93oBzczD6_pT",
        "outputId": "b0b95f4a-d487-4c4f-9329-4e5661c59c63"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-f51821f26a11>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Assuming folds are numbered 1 through 5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Load the data for the current fold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data_for_fold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Convert labels to one-hot encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-bf33298b6908>\u001b[0m in \u001b[0;36mload_data_for_fold\u001b[0;34m(fold)\u001b[0m\n\u001b[1;32m     23\u001b[0m                         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                         \u001b[0munique_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                         \u001b[0mimage_pil\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'L'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m                         \u001b[0mimage_resized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_resized\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3430\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3431\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3432\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3433\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "## TOO MUCH RAM\n",
        "\n",
        "fold_train_accuracies = []\n",
        "fold_val_accuracies = []\n",
        "fold_train_losses = []\n",
        "fold_val_losses = []\n",
        "\n",
        "# Parameters\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "num_classes = 12\n",
        "\n",
        "# Loop through each fold\n",
        "for fold in range(1, 6):  # Assuming folds are numbered 1 through 5\n",
        "    # Load the data for the current fold\n",
        "    (x_train, y_train), (x_test, y_test) = load_data_for_fold(fold)\n",
        "\n",
        "    # Convert labels to one-hot encoding\n",
        "    y_train = to_categorical(y_train, num_classes)\n",
        "    y_test = to_categorical(y_test, num_classes)\n",
        "\n",
        "    # Create TensorFlow datasets\n",
        "    train_dataset = create_tf_dataset(x_train, y_train, batch_size=batch_size, shuffle=True)\n",
        "    val_dataset = create_tf_dataset(x_test, y_test, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Initialize the model\n",
        "    model = alexnet_model(img_shape=(224, 224, 1), n_classes=num_classes)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    print(f\"Training fold {fold}...\")\n",
        "    model.fit(train_dataset, epochs=epochs, validation_data=val_dataset)\n",
        "\n",
        "    print(f\"Training fold {fold}...\")\n",
        "    history = model.fit(train_dataset, epochs=epochs, validation_data=val_dataset)\n",
        "\n",
        "    # Save the metrics for each epoch\n",
        "    fold_train_accuracies.append(history.history['accuracy'])\n",
        "    fold_val_accuracies.append(history.history['val_accuracy'])\n",
        "    fold_train_losses.append(history.history['loss'])\n",
        "    fold_val_losses.append(history.history['val_loss'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYSWfpVkEY7C"
      },
      "outputs": [],
      "source": [
        "# ONE FOLD\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "num_classes = 12\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = load_data_for_fold(1)\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)\n",
        "\n",
        "# Create TensorFlow datasets\n",
        "train_dataset = create_tf_dataset(x_train, y_train, batch_size=batch_size, shuffle=True)\n",
        "val_dataset = create_tf_dataset(x_test, y_test, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Initialize the model\n",
        "model = alexnet_model(img_shape=(224, 224, 1), n_classes=num_classes)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print(f\"Training...\")\n",
        "history = model.fit(train_dataset, epochs=epochs, validation_data=val_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ARfr__PU_CD"
      },
      "outputs": [],
      "source": [
        "# no preprocessing, return image paths and labels only\n",
        "def load_data_for_fold(fold):\n",
        "    train_image_paths = []\n",
        "    val_image_paths = []\n",
        "    train_labels = []\n",
        "    val_labels = []\n",
        "\n",
        "    fold_train_path = os.path.join('/content/drive/MyDrive/toybox_5fold', f'fold_{fold}', 'train')\n",
        "    fold_val_path = os.path.join('/content/drive/MyDrive/toybox_5fold', f'fold_{fold}', 'val')\n",
        "\n",
        "    directories = [fold_train_path, fold_val_path]\n",
        "    data_lists = [(train_image_paths, train_labels), (val_image_paths, val_labels)]\n",
        "\n",
        "    unique_labels = set()\n",
        "\n",
        "    for dataset, (image_paths, labels) in zip(directories, data_lists):\n",
        "        for class_folder in os.listdir(dataset):\n",
        "            class_path = os.path.join(dataset, class_folder)\n",
        "\n",
        "            if os.path.isdir(class_path):\n",
        "                for frame_file in os.listdir(class_path):\n",
        "                    if frame_file.endswith('.jpg'):\n",
        "                        frame_path = os.path.join(class_path, frame_file)\n",
        "                        label = frame_file.split('_')[0]\n",
        "                        unique_labels.add(label)\n",
        "                        image_paths.append(frame_path)\n",
        "                        labels.append(label)\n",
        "\n",
        "    # Map labels to indices\n",
        "    label_to_index = {label: idx for idx, label in enumerate(unique_labels)}\n",
        "    print(label_to_index)\n",
        "\n",
        "    # Convert labels to their respective indices\n",
        "    y_train = [label_to_index[label] for label in train_labels]\n",
        "    y_val = [label_to_index[label] for label in val_labels]\n",
        "\n",
        "    return (train_image_paths, y_train), (val_image_paths, y_val)\n",
        "\n",
        "def preprocess_image(image_path, label, target_size=(224, 224)):\n",
        "    # Load the image\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=1)  # Use channels=3 for RGB\n",
        "    image = tf.image.resize(image, target_size)\n",
        "    image = image / 255.0  # Normalize pixel values\n",
        "    label = to_categorical(label, num_classes=12)\n",
        "\n",
        "    return image, label\n",
        "\n",
        "def create_tf_dataset(image_paths, labels, batch_size=32, shuffle=True, target_size=(224, 224)):\n",
        "    # Create a dataset from the file paths and labels\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
        "    # Shuffle the dataset\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(buffer_size=len(image_paths))\n",
        "    # Preprocess each image\n",
        "    dataset = dataset.map(lambda x, y: preprocess_image(x, y, target_size),\n",
        "                          num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    # Batch the dataset\n",
        "    dataset = dataset.batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXyBjtgBVDbz",
        "outputId": "043e4f40-c57a-409b-f175-d4137be22a50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'helicopter': 0, 'spoon': 1, 'airplane': 2, 'mug': 3, 'duck': 4, 'cup': 5, 'car': 6, 'truck': 7, 'ball': 8, 'cat': 9, 'giraffe': 10, 'horse': 11}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training...\n",
            "\u001b[1m  78/1460\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:34:38\u001b[0m 22s/step - accuracy: 0.4204 - loss: 1.8783"
          ]
        }
      ],
      "source": [
        "# Parameters\n",
        "batch_size = 32\n",
        "epochs = 2\n",
        "learning_rate = 0.001\n",
        "num_classes = 12\n",
        "\n",
        "(x_train_paths, y_train), (x_val_paths, y_val) = load_data_for_fold(1)\n",
        "\n",
        "# Convert file paths and labels to TensorFlow datasets\n",
        "train_dataset = create_tf_dataset(x_train_paths, y_train, batch_size=batch_size, shuffle=True)\n",
        "val_dataset = create_tf_dataset(x_val_paths, y_val, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Initialize the model\n",
        "model = alexnet_model(img_shape=(224, 224, 1), n_classes=num_classes)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "print(f\"Training...\")\n",
        "history = model.fit(train_dataset, epochs=epochs, validation_data=val_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tz1ZDdGRJF9m"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# History for accuracy\n",
        "plt.subplot(211)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('AlexNet model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "\n",
        "# History for loss\n",
        "plt.subplot(212)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('AlexNet model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "\n",
        "plt.savefig('/content/drive/MyDrive/alexnet_loss_accuracy.png')\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}